from typing import override
import numpy as np
from scipy.sparse import diags, bmat
from scipy.sparse.linalg import spsolve
from scipy.sparse import csr_matrix
from tqdm import tqdm
from predictors import Predictor
from utils import average
from scipy.sparse.linalg import cg


class LeastSquaresPredictor(Predictor):
    """
    A least squares predictor trained with given training data.
    """

    lmda: float
    b: np.ndarray | None = None
    average_rating: float

    def __init__(self, lmda: float, shape: tuple[int, int]):
        """
        Initialize the least squares baseline predictor.

        Args:
            lmda (float): The regularization parameter.
            shape (tuple[int]): The shape of the training data.
        """
        self.lmda = lmda
        self.shape = shape

    @override
    def predict(self, entries, quiet=False):
        if self.b is None:
            raise RuntimeError("Predictor not trained yet.")
        output = [0.0] * len(entries)
        if not quiet:
            print("Predicting entries...")
        for idx, entry in enumerate(tqdm(entries, disable=quiet)):
            i, j = entry
            output[idx] = np.clip(
                self.average_rating + self.b[i] + self.b[self.shape[0] + j], 1, 5
            )
        if not quiet:
            print("Finished predicting entries.")
        return output

    @override
    def predict_all(self, quiet=False):
        if self.b is None:
            raise RuntimeError("Predictor not trained yet.")
        if not quiet:
            print("Predicting all...")
        data = np.zeros(shape=self.shape, dtype=np.float64)
        for i in range(self.shape[0]):
            for j in range(self.shape[1]):
                pred = self.average_rating + self.b[i] + self.b[self.shape[0] + j]
                data[i, j] = np.clip(pred, 1, 5)
        # prediction = csr_matrix((data, (rows, cols)), shape=self.shape)
        if not quiet:
            print("Finished predicting all.")
        return data

    def iterative_train(self, training_data: csr_matrix):
        """
        Train the predictor using an iterative optimization method (Conjugate Gradient)
        for solving the least squares problem.

        Generated by o3-mini, based on `train`.
        """
        print("Constructing relevant matrices for iterative training...", flush=True)
        # Compute average rating and adjust the training data matrix
        self.average_rating = average(training_data)
        C: csr_matrix = training_data.copy()
        C.data = C.data - self.average_rating

        # Sum centered ratings per user and per item
        uc = np.array(C.sum(axis=1)).flatten()
        ic = np.array(C.sum(axis=0)).flatten()
        rhs = np.concatenate([uc, ic])

        # Count non-zero ratings per user and per item
        N_u = training_data.getnnz(axis=1)
        N_i = training_data.getnnz(axis=0)

        # Build diagonal matrices with regularization added
        U = diags(N_u + self.lmda)
        I = diags(N_i + self.lmda)

        # Create the sparse mask matrix M: known ratings indicator
        M = training_data.copy()
        M.data = np.ones_like(M.data)

        # Build the sparse system matrix
        ATA = bmat([[U, M], [M.T, I]], format="csr")
        print(
            "Calculating user and item biases using Conjugate Gradient...", flush=True
        )
        # Solve the linear system iteratively
        maxiter = 10000
        with tqdm(total=maxiter) as pbar:
            self.b, info = cg(
                ATA, rhs, maxiter=maxiter, callback=lambda _: pbar.update(1)
            )
        if info != 0:
            print(f"Conjugate Gradient did not converge (info={info}).")
        print("Training done.")

    @override
    def train(self, training_data):
        """
        Train the predictor using the training data using sparse matrices.

        Optimized by o3-mini from `old_train`.
        """
        print("Constructing relevant matrices...", flush=True)
        # number of ratings per user u and per item i (non-zero entries)
        N_u = training_data.getnnz(axis=1)  # shape (n,)
        N_i = training_data.getnnz(axis=0)  # shape (m,)

        self.average_rating = average(training_data)

        C: csr_matrix = training_data.copy()
        C.data = C.data - self.average_rating
        uc = np.array(C.sum(axis=1)).flatten()
        ic = np.array(C.sum(axis=0)).flatten()
        rhs = np.concatenate([uc, ic])

        U = diags(N_u + self.lmda)
        I = diags(N_i + self.lmda)
        # off‚Äêdiagonals: rating adjacency as sparse
        # build sparse mask matrix M where nonzero entries indicate known ratings
        M = training_data.copy()
        M.data = np.ones_like(M.data)
        ATA = bmat([[U, M], [M.T, I]], format="csr")
        print("Calculating user and item biases...", flush=True)
        self.b = spsolve(ATA, rhs)
        print("Training done.")

    def old_train(self, training_data: csr_matrix):
        """
        Train the predictor naively using the training data.
        """
        n, m = self.shape
        a = np.zeros(shape=(n * m, n + m), dtype=np.float64)
        c = np.zeros(shape=(n * m, 1), dtype=np.float64)

        curr_col = 0

        for i, row in enumerate(training_data):
            for j, col in enumerate(row):
                if np.ma.is_masked(col):
                    continue
                a[curr_col, i] = 1
                a[curr_col, n + j] = 1
                c[curr_col, 0] = col - self.average_rating
                curr_col += 1

        a = a[:curr_col, :]
        a_transpose = a.T
        c = c[:curr_col, :]
        self.b = np.linalg.solve(
            a_transpose @ a + self.lmda * np.identity(a_transpose.shape[0]),
            a_transpose @ c,
        )
